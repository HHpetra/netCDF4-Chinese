{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# netCDF module\n",
    "Version 1.5.1.2\n",
    "\n",
    "# 介绍\n",
    "netcdf-python 是Python关于netCDF的一个库。\n",
    "netCDF4添加了许多之前版本没有的特性，并且是在HDF5的基础上实现的。这个模块可以读取和写入新的netCDF4和旧的netCDF3格式，并且可以创建HDF5程序可读的文件。这个模块模仿[Scientific.IO.NetCDF](http://dirac.cnrs-orleans.fr/ScientificPython/)，并且该模块用户们应该熟悉。  \n",
    "许多netCDF4特性已经实现，例如多个无限维度，组和zlib数据压缩。所有新的数据类型（如64位无符号的整形）都已经实现。Compound (struct), variable length (vlen) 和 enumerated (enum) 数据类型都支持，但是目前还不支持opaque 数据类型。混合的compound, vlen 和 enum 数据类型（如compound中包含enums或者vlen中包含compound）也不支持。\n",
    "\n",
    "# 下载\n",
    "* 来自github最新的代码。\n",
    "* 最新版本(源代码和二进制安装程序)。\n",
    "\n",
    "# 依赖环境\n",
    "* Python 2.7 or later (python 3 works too).\n",
    "* numpy array module, version 1.10.0 or later.\n",
    "* Cython, version 0.21 or later.\n",
    "* setuptools, version 18.0 or later.\n",
    "* cftime for the time and date handling utility functions (num2date, date2num and date2index).\n",
    "* The HDF5 C library version 1.8.4-patch1 or higher (1.8.x recommended) from . netCDF version 4.4.1 or higher is recommended if using HDF5 1.10.x - otherwise resulting files may be unreadable by clients using earlier versions of HDF5. For netCDF < 4.4.1, HDF5 version 1.8.x is recommended. Be sure to build with --enable-hl --enable-shared.\n",
    "* Libcurl, if you want OPeNDAP support.\n",
    "* HDF4, if you want to be able to read HDF4 \"Scientific Dataset\" (SD) files.\n",
    "* The netCDF-4 C library from the github releases page. Version 4.1.1 or higher is required (4.2 or higher recommended). Be sure to build with --enable-netcdf-4 --enable-shared, and set CPPFLAGS=\"-I \\\\&#36; HDF5_DIR/include\" and LDFLAGS=\"-L \\\\&#36;HDF5_DIR/lib\", where\\\\&#36;HDF5_DIR is the directory where HDF5 was installed. If you want OPeNDAP support, add --enable-dap. If you want HDF4 SD support, add --enable-hdf4 and add the location of the HDF4 headers and library to \\\\&#36;CPPFLAGS and \\\\&#36;LDFLAGS.  \n",
    "* for MPI parallel IO support, an MPI-enabled versions of the netcdf library is required, as is the mpi4py python module. Parallel IO further depends on the existence of MPI-enabled HDF5 or the PnetCDF library.  \n",
    "\n",
    "# 安装\n",
    "推荐使用anaconda安装：  \n",
    "`conda install netCDF4`  \n",
    "* install the requisite python modules and C libraries (see above). It's easiest if all the C libs are built as shared libraries.  \n",
    "* By default, the utility nc-config, installed with netcdf 4.1.2 or higher, will be run used to determine where all the dependencies live.  \n",
    "* If nc-config is not in your default \\\\&#36;PATH edit the setup.cfg file in a text editor and follow the instructions in the comments. In addition to specifying the path to nc-config, you can manually set the paths to all the libraries and their include files (in case nc-config does not do the right thing).\n",
    "* run python setup.py build, then python setup.py install (as root if necessary).\n",
    "* pip install can also be used, with library paths set with environment variables. To make this work, the USE_SETUPCFG environment variable must be used to tell setup.py not to use setup.cfg. For example, USE_SETUPCFG=0 HDF5_INCDIR=/usr/include/hdf5/serial HDF5_LIBDIR=/usr/lib/x86_64-linux-gnu/hdf5/serial pip install has been shown to work on an Ubuntu/Debian linux system. Similarly, environment variables (all capitalized) can be used to set the include and library paths for hdf5, netCDF4, hdf4, szip, jpeg, curl and zlib. If the libraries are installed in standard places (e.g. /usr or /usr/local), the environment variables do not need to be set.\n",
    "* run the tests in the 'test' directory by running python run_all.py.\n",
    "\n",
    "# 教程\n",
    "\n",
    "## 创建、打开和关闭一个netCDF文件\n",
    "使用python创建一个netCDF文件，你只需要使用`Dataset`构造器。这也是打开一个已存在的netCDF文件的方法。如果以读写模式（mode='w', 'r+' or 'a'）打开文件，你可以写入任何类型的数据，包括新的dimensions, groups, variables and attributes。netCDF文件有5中类型（NETCDF3_CLASSIC, NETCDF3_64BIT_OFFSET, NETCDF3_64BIT_DATA, NETCDF4_CLASSIC, and NETCDF4）。NETCDF3_CLASSIC是原始的netcdf二进制格式，限制2Gb以内的文件。默认的打开格式是NETCDF4。你可以检查data_model 属性确认打开的文件格式。当文件写入完成时，通过 `Dataset`中的 `close`关闭文件。  \n",
    "例子如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "rootgrp = Dataset('data/test.nc','w',format='NETCDF4')\n",
    "print(rootgrp.data_model)\n",
    "rootgrp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "远程OPeNDAP-hosted数据集可以通过HTTP获取，将`Dataset`中的文件名改成URL地址即可。这需要netCDF库支持OPenDAP，在构建时使用`--enable-drap`参数。\n",
    "## netCDF文件中的组Groups\n",
    "netCDF4支持层级结构的group组织数据，类似于文件系统中的目录结构。group充当variables, dimensions 和 attributes,及其它组的容器。`Dataset`创建一种特殊的组叫做'root group'，类似于unix系统中的根目录。要创建group实例，请使用`Dataset`或者`Group`实例的`createGroup`方法。`createGroup`包含一个参数，一个表示组名的python字符串。可以使用`Dataset`实例的`groups dictionary`属性按名称访问根组中包含的新组实例。只有NETCDF4格式支持组操作，如果你尝试使用NETCDF3创建一个组会得到错误信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('forecasts', <class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "), ('analyses', <class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "rootgrp=Dataset('data/test.nc','a')\n",
    "fctgrp=rootgrp.createGroup('forecasts')\n",
    "analgrp=rootgrp.createGroup('analyses')\n",
    "print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group可以存在于Dataset中的group里，就像unix文件系统中目录下还存在目录。每个group实例都有一个`groups`属性字典包含了该组内所有的group实例。每个group实例都有`path`属性包含类似于unix路径的组路径。为了简化嵌套组的创建，你可以使用类似unix的路径作为参数创建组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcstgrp1 = rootgrp.createGroup(\"/forecasts/model1\")\n",
    "fcstgrp2 = rootgrp.createGroup(\"/forecasts/model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果中间的任何路径不存在它将会自动创建，就好比unix的命令`mkdir -p`。如果你试图创建任何已存在的组，不会提示错误，将会返回该存在的组。  \n",
    "这是一个遍历所有`Dataset`下的group。python中的`walktree`迭代器又来遍历树节点。注意，print `Dataset`或者`Group`对象将会返回其内容的摘要信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: forecasts, analyses\n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: model1, model2\n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model1:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model2:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def walktree(top):\n",
    "     values = top.groups.values()\n",
    "     yield values\n",
    "     for value in top.groups.values():\n",
    "         for children in walktree(value):\n",
    "             yield children\n",
    "print(rootgrp)\n",
    "for children in walktree(rootgrp):\n",
    "      for child in children:\n",
    "          print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF文件中的维度Dimensions\n",
    "netCDF使用维度定义所有变量的大小。因此在创建任何变量之前，需要先创建维度。一个特殊的情况，一般实际中不会出现，如一个没有维度的标量。使用`Dataset`和`Group`实例的`createDimension`方法创建维度。用python字符串来表示维度的名字，用整型来表示维度的大小。使用`None`或者0来创建无限维度（可以扩展的维度）。在这个例子中`time`和`level`都是无限的。拥有不止一个无限维度是netCDF4的特性，在netCDF3中， 只能有一个无限维度，而且必须作为第一个变量的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = rootgrp.createDimension('level',None)\n",
    "time = rootgrp.createDimension('time',None)\n",
    "lat = rootgrp.createDimension('lat',73)\n",
    "lon = rootgrp.createDimension('lon',144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的维度将储存在一个python字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('level', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\n",
      "), ('time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "), ('lat', <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\n",
      "), ('lon', <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用python的`len`函数可以获取`Dimension`实例的当前长度，`Dimension`实例的`isunlimited`方法可以确认维度是否是无限或者可扩展的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(lon))\n",
    "print(lon.isunlimited())\n",
    "print(time.isunlimited())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接输出`Dimension`对象可以获取概况信息。包含该维度的名字和长度以及是否是无限的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dimobj in rootgrp.dimensions.values():\n",
    "    print(dimobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dimension`名字可以更改，使用`Dataset`和`Group`实例的`netCDF4.Dataset.renameDimension`方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF文件中的变量\n",
    "netCDF变量就好比python中numpy的多维度矩阵。然而，和numpy矩阵不同的是，netCDF可以沿着不止一个无限维度扩展。使用`Dataset`和`Group`实例的`createVariable`方法创建netCDF变量。`createVariable`方法有两个必填参数，一是变量名字，二是变量的数据类型。变量的维度通过一个包含维度名字的tuple给出。创建一个标量，不填维度参数就可以了。变量基本数据类型对应于numpy数组的数据类型。  \n",
    "维度也可以定义成变量，叫作坐标变量。`createVariable`方法会返回一个变量实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = rootgrp.createVariable('time','f8',('time',))\n",
    "levels = rootgrp.createVariable('level','i4',('level',))\n",
    "latitudes = rootgrp.createVariable('lat','f4',('lat',))\n",
    "longitudes = rootgrp.createVariable('lon','f4',('lon',))\n",
    "temp = rootgrp.createVariable('temp','f4',('time','level','lat','lon',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了查看变量实例的概况，直接输出即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, level, lat, lon)\n",
      "unlimited dimensions: time, level\n",
      "current shape = (0, 0, 73, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以使用路径来一个组里创建变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftemp = rootgrp.createVariable('/forecasts/model1/temp','f4',('time','level','lat','lon',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果中间组不存在，那么将会自动创建。  \n",
    "你也可以通过`Dataset`和`Group`路径查询`Dataset`和`Group`实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model1:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): float32 \u001b[4mtemp\u001b[0m(time,level,lat,lon)\n",
      "    groups: \n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, level, lat, lon)\n",
      "path = /forecasts/model1\n",
      "unlimited dimensions: time, level\n",
      "current shape = (0, 0, 73, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp['/forecasts/model1'])\n",
    "print(rootgrp['/forecasts/model1/temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有`Dataset`和`Group`里的变量都存储在python字典中。就和维度一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('time', <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "unlimited dimensions: time\n",
      "current shape = (0,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('level', <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 level(level)\n",
      "unlimited dimensions: level\n",
      "current shape = (0,)\n",
      "filling on, default _FillValue of -2147483647 used\n",
      "), ('lat', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lat(lat)\n",
      "unlimited dimensions: \n",
      "current shape = (73,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('lon', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lon(lon)\n",
      "unlimited dimensions: \n",
      "current shape = (144,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('temp', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, level, lat, lon)\n",
      "unlimited dimensions: time, level\n",
      "current shape = (0, 0, 73, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量可以通过`Dataset`中的`renameVariable`方法重新命名。  \n",
    "## netCDF文件的属性\n",
    "netCDF文件中有两种类型的属性，全局和变量。全局属性提供组或者整个数据的信息。变量属性提供组里变量的属性。通过为`Dataset`和`Group`实例变量分配值来设置全局属性。变量的属性可以通过`Variable`实例的值来设定。属性可以是字符串、数字或者序列。以下是一个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "rootgrp.description = 'bogus example script'\n",
    "rootgrp.history = 'Created'+time.ctime(time.time())\n",
    "rootgrp.source = 'netCDF4 python module tutorial'\n",
    "latitudes.units = 'degrees north'\n",
    "longitudes.units = 'degrees east'\n",
    "levels.units = 'hPa'\n",
    "temp.units = 'K'\n",
    "times.units = 'hour since 0001-01-01 00:00:00.0'\n",
    "times.calendar = 'gregorian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset`、`Group`或者`Variable`实例中的`__dict__`属性提供netCDF4文件中所有属性的名字和值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('description', 'bogus example script'), ('history', 'CreatedWed May  8 15:35:37 2019'), ('source', 'netCDF4 python module tutorial')])\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用python`del`语句从`Dataset`、`Group`中删除某个属性。如`del grp.foo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rootgrp.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从netCDF文件中写入或检索数据\n",
    "现在你已经有一个netCDF变量实例，怎么讲数据写入呢？你只需要像操作数组那样操作它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitudes = \n",
      " [-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\n",
      " -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\n",
      " -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\n",
      "   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\n",
      "  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\n",
      "  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\n",
      "  90. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lats = np.arange(-90,91,2.5)\n",
    "lons = np.arange(-180,180,2.5)\n",
    "latitudes[:] = lats\n",
    "longitudes[:] = lons\n",
    "print(\"latitudes = \\n\",latitudes[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和numpy不同，如果您将数据分配到当前定义的索引范围之外，则具有无限维度的netCDF变量对象将沿着这些维度增长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp shape before adding data =  (0, 0, 73, 144)\n",
      "temp shape after adding data =  (5, 10, 73, 144)\n",
      "levels shape after adding pressre data =  (10,)\n"
     ]
    }
   ],
   "source": [
    "nlats = len(rootgrp.dimensions['lat'])\n",
    "nlons = len(rootgrp.dimensions['lon'])\n",
    "print('temp shape before adding data = ',temp.shape)\n",
    "temp[0:5,0:10,:,:] = np.random.uniform(size=(5,10,nlats,nlons))\n",
    "print('temp shape after adding data = ',temp.shape)\n",
    "print('levels shape after adding pressre data = ',levels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，当沿着temp变量的level维度添加数据时，levels变量的维度也会跟着增加，虽然还没有往里填入数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels[:] = [1000.,850.,700.,500.,300.,250.,200.,150.,100.,50.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然，Numpy和netCDF的切片规则有一些不同，但是基本一致。需要注意的是虽然netCDF支持布尔索引，但是只能支持一个维度的布尔值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[0.9379823 , 0.53990453, 0.62666005, 0.9069424 ],\n",
       "        [0.9756705 , 0.16037382, 0.20512678, 0.61722106],\n",
       "        [0.726117  , 0.54609185, 0.3154905 , 0.92369676],\n",
       "        [0.85004926, 0.05542484, 0.44301683, 0.5743179 ]],\n",
       "  mask=False,\n",
       "  fill_value=1e+20,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0, 0, [0,1,2,3], [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9379823  0.62666005 0.9756705  0.20512678 0.726117   0.3154905\n",
      " 0.85004926 0.44301683]\n",
      "[0.9379823  0.53990453 0.62666005 0.9069424 ]\n"
     ]
    }
   ],
   "source": [
    "a=temp[0, 0, [0,1,2,3], [0,1,2,3]]\n",
    "print(a[np.array([[True,False,True,False],[True,False,True,False],[True,False,True,False],[True,False,True,False]])])\n",
    "print(a[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 36, 71)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdat = temp[::2, [1,3,6], lats>0, lons>0]\n",
    "tempdat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理时间坐标\n",
    "时间坐标给netCDF用户带来特殊的挑战。大多数元数据标准（如CF）指定，时间应该使用特定相对于固定日期的日历，单位指定为YY-MM-DD hh:mm:ss之后的小时数。如果没有将值转换为日历日期或者从日历日期转换过来的程序，这种单位将很难处理。名叫`num2date`和`date2num`的函数提供这个功能。以下是一个使用它们的例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time values (in units hour since 0001-01-01 00:00:00.0):\n",
      " [17533104. 17533116. 17533128. 17533140. 17533152.]\n",
      "dates corresponding to time values:\n",
      " [real_datetime(2001, 3, 1, 0, 0) real_datetime(2001, 3, 1, 12, 0)\n",
      " real_datetime(2001, 3, 2, 0, 0) real_datetime(2001, 3, 2, 12, 0)\n",
      " real_datetime(2001, 3, 3, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num\n",
    "dates = [datetime(2001,3,1)+n*timedelta(hours=12) for n in range(temp.shape[0])]\n",
    "times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n",
    "print('time values (in units %s):' %times.units+'\\n',times[:])\n",
    "dates = num2date(times[:],units=times.units,calendar=times.calendar)\n",
    "print('dates corresponding to time values:\\n',dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num2date`将指定单位和日历中的时间数值转换为`datetime`对象，而`date2time`执行相反的操作。支持单签在CF元数据中定义的所有日历。还提供了一个名叫`date2index`的函数，该函数返回一系列datetime实例对应的时间变量索引。  \n",
    "## 从多文件中读取netCDF数据\n",
    "如果你需要从多个文件中读取netCDF数据，你可以使用`MFDataset`类读取数据，即使只含有一个文件。不要使用单个文件名来创建数据集实例，而是使用文件名列表或通配符字符串(然后使用python glob模块将其转换为已排序的文件列表)创建MFDataset实例。共享相同无限维度的文件列表中的变量聚合在一起，可以跨多个文件进行切片。为了阐述这点，让我们先创建含有相同变量的一串netCDF文件（有相同的无限维度）。目前还不支持NETCDF4格式的文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nf in range(10):\n",
    "    f = Dataset(\"data/mftest%s.nc\" % nf,\"w\",format='NETCDF4_CLASSIC')\n",
    "    f.createDimension(\"x\",None)\n",
    "    x = f.createVariable(\"x\",\"i\",(\"x\",))\n",
    "    x[0:10] = np.arange(nf*10,10*(nf+1))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在来一次性读取它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import MFDataset\n",
    "f = MFDataset('data/mftest*.nc')\n",
    "print(f.variables[\"x\"][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高效的压缩netCDF变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = rootgrp.createVariable(\"data/temp1\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",))\n",
    "temp2 = rootgrp.createVariable(\"data/temp2\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",),zlib=True)\n",
    "temp3 = rootgrp.createVariable(\"data/temp3\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",),zlib=True,least_significant_digit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面的太高级了，懒得翻译了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
