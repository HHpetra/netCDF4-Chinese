{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# netCDF module\n",
    "Version 1.5.1.2\n",
    "\n",
    "# 介绍\n",
    "netcdf-python 是Python关于netCDF的一个库。\n",
    "netCDF4添加了许多之前版本没有的特性，并且是在HDF5的基础上实现的。这个模块可以读取和写入新的netCDF4和旧的netCDF3格式，并且可以创建HDF5程序可读的文件。这个模块模仿[Scientific.IO.NetCDF](http://dirac.cnrs-orleans.fr/ScientificPython/)，并且该模块用户们应该熟悉。  \n",
    "许多netCDF4特性已经实现，例如多个无限维度，组和zlib数据压缩。所有新的数据类型（如64位无符号的整形）都已经实现。Compound (struct), variable length (vlen) 和 enumerated (enum) 数据类型都支持，但是目前还不支持opaque 数据类型。混合的compound, vlen 和 enum 数据类型（如compound中包含enums或者vlen中包含compound）也不支持。\n",
    "\n",
    "# 下载\n",
    "* 来自github最新的代码。\n",
    "* 最新版本(源代码和二进制安装程序)。\n",
    "\n",
    "# 依赖环境\n",
    "* Python 2.7 or later (python 3 works too).\n",
    "* numpy array module, version 1.10.0 or later.\n",
    "* Cython, version 0.21 or later.\n",
    "* setuptools, version 18.0 or later.\n",
    "* cftime for the time and date handling utility functions (num2date, date2num and date2index).\n",
    "* The HDF5 C library version 1.8.4-patch1 or higher (1.8.x recommended) from . netCDF version 4.4.1 or higher is recommended if using HDF5 1.10.x - otherwise resulting files may be unreadable by clients using earlier versions of HDF5. For netCDF < 4.4.1, HDF5 version 1.8.x is recommended. Be sure to build with --enable-hl --enable-shared.\n",
    "* Libcurl, if you want OPeNDAP support.\n",
    "* HDF4, if you want to be able to read HDF4 \"Scientific Dataset\" (SD) files.\n",
    "* The netCDF-4 C library from the github releases page. Version 4.1.1 or higher is required (4.2 or higher recommended). Be sure to build with --enable-netcdf-4 --enable-shared, and set CPPFLAGS=\"-I \\\\&#36; HDF5_DIR/include\" and LDFLAGS=\"-L \\\\&#36;HDF5_DIR/lib\", where\\\\&#36;HDF5_DIR is the directory where HDF5 was installed. If you want OPeNDAP support, add --enable-dap. If you want HDF4 SD support, add --enable-hdf4 and add the location of the HDF4 headers and library to \\\\&#36;CPPFLAGS and \\\\&#36;LDFLAGS.  \n",
    "* for MPI parallel IO support, an MPI-enabled versions of the netcdf library is required, as is the mpi4py python module. Parallel IO further depends on the existence of MPI-enabled HDF5 or the PnetCDF library.  \n",
    "\n",
    "# 安装\n",
    "推荐使用anaconda安装：  \n",
    "`conda install netCDF4`  \n",
    "* install the requisite python modules and C libraries (see above). It's easiest if all the C libs are built as shared libraries.  \n",
    "* By default, the utility nc-config, installed with netcdf 4.1.2 or higher, will be run used to determine where all the dependencies live.  \n",
    "* If nc-config is not in your default \\\\&#36;PATH edit the setup.cfg file in a text editor and follow the instructions in the comments. In addition to specifying the path to nc-config, you can manually set the paths to all the libraries and their include files (in case nc-config does not do the right thing).\n",
    "* run python setup.py build, then python setup.py install (as root if necessary).\n",
    "* pip install can also be used, with library paths set with environment variables. To make this work, the USE_SETUPCFG environment variable must be used to tell setup.py not to use setup.cfg. For example, USE_SETUPCFG=0 HDF5_INCDIR=/usr/include/hdf5/serial HDF5_LIBDIR=/usr/lib/x86_64-linux-gnu/hdf5/serial pip install has been shown to work on an Ubuntu/Debian linux system. Similarly, environment variables (all capitalized) can be used to set the include and library paths for hdf5, netCDF4, hdf4, szip, jpeg, curl and zlib. If the libraries are installed in standard places (e.g. /usr or /usr/local), the environment variables do not need to be set.\n",
    "* run the tests in the 'test' directory by running python run_all.py.\n",
    "\n",
    "# 教程\n",
    "\n",
    "## 创建、打开和关闭一个netCDF文件\n",
    "使用python创建一个netCDF文件，你只需要使用`Dataset`构造器。这也是打开一个已存在的netCDF文件的方法。如果以读写模式（mode='w', 'r+' or 'a'）打开文件，你可以写入任何类型的数据，包括新的dimensions, groups, variables and attributes。netCDF文件有5中类型（NETCDF3_CLASSIC, NETCDF3_64BIT_OFFSET, NETCDF3_64BIT_DATA, NETCDF4_CLASSIC, and NETCDF4）。NETCDF3_CLASSIC是原始的netcdf二进制格式，限制2Gb以内的文件。默认的打开格式是NETCDF4。你可以检查data_model 属性确认打开的文件格式。当文件写入完成时，通过 `Dataset`中的 `close`关闭文件。  \n",
    "例子如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "rootgrp = Dataset('data/test.nc','w',format='NETCDF4')\n",
    "print(rootgrp.data_model)\n",
    "rootgrp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "远程OPeNDAP-hosted数据集可以通过HTTP获取，将`Dataset`中的文件名改成URL地址即可。这需要netCDF库支持OPenDAP，在构建时使用`--enable-drap`参数。\n",
    "## netCDF文件中的组Groups\n",
    "netCDF4支持层级结构的group组织数据，类似于文件系统中的目录结构。group充当variables, dimensions 和 attributes,及其它组的容器。`Dataset`创建一种特殊的组叫做'root group'，类似于unix系统中的根目录。要创建group实例，请使用`Dataset`或者`Group`实例的`createGroup`方法。`createGroup`包含一个参数，一个表示组名的python字符串。可以使用`Dataset`实例的`groups dictionary`属性按名称访问根组中包含的新组实例。只有NETCDF4格式支持组操作，如果你尝试使用NETCDF3创建一个组会得到错误信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('forecasts', <class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "), ('analyses', <class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "rootgrp=Dataset('data/test.nc','a')\n",
    "fctgrp=rootgrp.createGroup('forecasts')\n",
    "analgrp=rootgrp.createGroup('analyses')\n",
    "print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group可以存在于Dataset中的group里，就像unix文件系统中目录下还存在目录。每个group实例都有一个`groups`属性字典包含了该组内所有的group实例。每个group实例都有`path`属性包含类似于unix路径的组路径。为了简化嵌套组的创建，你可以使用类似unix的路径作为参数创建组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcstgrp1 = rootgrp.createGroup(\"/forecasts/model1\")\n",
    "fcstgrp2 = rootgrp.createGroup(\"/forecasts/model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果中间的任何路径不存在它将会自动创建，就好比unix的命令`mkdir -p`。如果你试图创建任何已存在的组，不会提示错误，将会返回该存在的组。  \n",
    "这是一个遍历所有`Dataset`下的group。python中的`walktree`迭代器又来遍历树节点。注意，print `Dataset`或者`Group`对象将会返回其内容的摘要信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: forecasts, analyses\n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: model1, model2\n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model1:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model2:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def walktree(top):\n",
    "     values = top.groups.values()\n",
    "     yield values\n",
    "     for value in top.groups.values():\n",
    "         for children in walktree(value):\n",
    "             yield children\n",
    "print(rootgrp)\n",
    "for children in walktree(rootgrp):\n",
    "      for child in children:\n",
    "          print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF文件中的维度Dimensions\n",
    "netCDF使用维度定义所有变量的大小。因此在创建任何变量之前，需要先创建维度。一个特殊的情况，一般实际中不会出现，如一个没有维度的标量。使用`Dataset`和`Group`实例的`createDimension`方法创建维度。用python字符串来表示维度的名字，用整型来表示维度的大小。使用`None`或者0来创建无限维度（可以扩展的维度）。在这个例子中`time`和`level`都是无限的。拥有不止一个无限维度是netCDF4的特性，在netCDF3中， 只能有一个无限维度，而且必须作为第一个变量的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = rootgrp.createDimension('level',None)\n",
    "time = rootgrp.createDimension('time',None)\n",
    "lat = rootgrp.createDimension('lat',73)\n",
    "lon = rootgrp.createDimension('lon',144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的维度将储存在一个python字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('level', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\n",
      "), ('time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "), ('lat', <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\n",
      "), ('lon', <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用python的`len`函数可以获取`Dimension`实例的当前长度，`Dimension`实例的`isunlimited`方法可以确认维度是否是无限或者可扩展的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(lon))\n",
    "print(lon.isunlimited())\n",
    "print(time.isunlimited())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接输出`Dimension`对象可以获取概况信息。包含该维度的名字和长度以及是否是无限的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dimobj in rootgrp.dimensions.values():\n",
    "    print(dimobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dimension`名字可以更改，使用`Dataset`和`Group`实例的`netCDF4.Dataset.renameDimension`方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF文件中的变量\n",
    "netCDF变量就好比python中numpy的多维度矩阵。然而，和numpy矩阵不同的是，netCDF可以沿着不止一个无限维度扩展。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
